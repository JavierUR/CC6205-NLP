{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X4lL5hGw07yP"
   },
   "source": [
    "# Minitarea 4\n",
    "\n",
    "Por favor, en las respuestas de desarrollo expliquen lo que están haciendo. En las preguntas que son con desarrollo matemático pongan todos los pasos del cálculo (déjenlo bonito porfis :D).\n",
    "\n",
    "Usen $\\LaTeX$ para las fórmulas matemáticas.\n",
    "\n",
    "En la parte de programación pueden usar lo que quieran, pero la auxiliar 3 les puede servir de *inspiración*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bWXD3D7RYKJ-"
   },
   "source": [
    "# Hidden Markov Models (HMM), Maximum Entropy Markov Models (MEMM) and Conditional Random Field(CRF)\n",
    "\n",
    "### Pregunta 1 (1 pt)\n",
    "Para un problema de POS tagging se define el conjunto de etiquetas $S = \\{ D, N, V, P \\}$ y se tiene un Hidden Markov Model con los siguientes parámetros estimados a partir de un corpus de entrenamiento:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "q(D|N,P) &= 0.4 \\\\\n",
    "q(D|w,P) &= 0 \\qquad \\forall w \\in S, w \\neq N \\\\\n",
    "e(the|D) &= 0.6\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Luego para la oración: `Ella walks to the red house`, se tiene una tabla de programación dinámica con los siguientes valores:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\pi(3,D,P)&=0.1\\\\\n",
    "\\pi(3,N,P)&=0.2\\\\\n",
    "\\pi(3,V,P)&=0.01\\\\\n",
    "\\pi(3,P,P)&=0.5\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Con esta información, calcule el valor de $\\pi(4,P,D)$. Puede dejar el resultado expresado como una fracción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5EzgysW9kGi-"
   },
   "source": [
    "**Respuesta**\n",
    "\n",
    "Se tiene $\\pi (4,P,D) = max_{w\\in S_2}(\\pi (3,w,P)\\times q(D|w,P)\\times e(x_4,D))$ , por lo que se busca la etiqueta $w$ entre las posibles para la palabra \"walks\". Como $q(D|w,P)$ es 0 para etiquetas distintas de N, el máximo será con $w=N$. Luego $\\pi (4,P,D) = 0.2*0.4*0.6=0.048$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oiwJb_vmkKLZ"
   },
   "source": [
    "### Pregunta 2 (0.5 pts)\n",
    "Comente  sobre las similitudes o diferencias entre los HMMs, MEMMs y CRFs. Para esto, responda las siguientes preguntas.\n",
    "* ¿Para qué tipo de tarea sirven? Dé dos ejemplo de este tipo de tarea y descríbalos brevemente.\n",
    "* ¿Qué modelos usan features? ¿Qué ventajas conlleva esto?\n",
    "* ¿Cómo maneja cada uno de los modelos las palabras con baja frecuencia en el set de train?\n",
    "* ¿Qué le permite a los CRF realizar decisiones globales? ¿Qué diferencia con respecto a los MEMMs permite lograr esto? ¿Por qué los HMMs tampoco son capaces de tomar decisiones globales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P9h5ow8OWF7y"
   },
   "source": [
    "**Respuesta**\n",
    "* Este tipo de algoritmos permiten resolver problemas de secuencias de etiquetado. Uno de estos es Part of Speech tagging, donde a cada palabra de una frase se le asigna una etiqueta según la función que tiene en la oración. Otro es Named Entity recognition donde a cada entidad que aparesca en una frase se le asigna una etiqueta que indica su tipo, como el nombre de una compañía o nombre de una persona.\n",
    "* Los modelos MEMMs y CRF utilizan features. La ventaja de utilizarlas es que permiten representaciones más ricas de la entrada y que permiten discriminar mejor.\n",
    "* Un método simple que funciona en los tres es separar el vocabulario en las palabras frecuentes y menos frecuentes. Luego, las palabras menos frecuentes se mapean a un conjunto finito de clases de palabra, que se definen por características como la cantidad de digitos, si empiezan por mayuscilas, si tiene solo minuscula, etc.\n",
    "* Lo que le permite a los CRF tomar decisiones globales es que directamente modelan la probabilidad conjunta $P(s_1,...,s_m|x_1,...,x_m)$ que es el conjunto total de etiquetas dado todas las palabras en la frase. En cambio los modelos MEMM se realiza un supuesto de Markov de primer orden para expresar esa probabilidad como $\\prod_{m}^{i=1}P(s_i|s_{i-1},x_1,...,x_m)$. Esto hace que cada etiqueta dependa localmente de la etiqueta anterior. En los modelos HMMs ocurre lo mismo pues intentan modelar la probabilidad $P(s_1,...,s_m,x_1,...,x_m)$ realizando un supuesto de independencia,quedando como $q(STOP|s_{m-1},s_m)\\prod_{m}^{i=1}q(s_i|s_{i-1},s_i)\\prod_{m}^{i=1}q(x_i|s_i)$. En esa epxresión tambien la decision queda sujeta a un entorno local de cada etiqueta predicha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ClRAHR95Y8aB"
   },
   "source": [
    "# Convolutional Neural Networks\n",
    "### Pregunta 3 (1 pt)\n",
    "\n",
    "Considere la frase $w_{1..7}=$ `El agua moja y el fuego quema` $=[El, agua, moja, y, el, fuego, quema]$.\n",
    "\n",
    "La siguiente matriz de embeddings, donde la i-ésima fila corresponde al vector de embedding de la i-ésima palabra, ordenadas segun aparecen en la frase. (vectores de largo 2).\n",
    "\\begin{equation}\n",
    "E = \\begin{pmatrix}\n",
    "2 & 2\\\\\n",
    "0 & -2\\\\\n",
    "0 & 1\\\\\n",
    "-2 & 1\\\\\n",
    "-2 & 0\\\\\n",
    "2 & -1\\\\\n",
    "0 & 2\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Los siguientes 3 filtros\n",
    "\\begin{equation}\n",
    "U = \\begin{pmatrix}\n",
    "-1 & -1 & 0\\\\\n",
    "1 & 1 & 0\\\\\n",
    "0 & 0 & -1\\\\\n",
    "-1 & -1 & -1\\\\\n",
    "-1 & -1 & 1\\\\\n",
    "1 & 0 & -1\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Y la función de activación\n",
    "\\begin{equation}\n",
    "tanh = \\frac{e^{2x} - 1}{e^{2x} + 1}\n",
    "\\end{equation}\n",
    "\n",
    "Usando estos paramátros calcule manualmente la representación (vector) resultante de aplicar la operación de convolución (sin padding) + max pooling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SlQ30Arkq0u4"
   },
   "source": [
    "**Respuesta**\n",
    "Como como los filtros son de largo 6 y el embedding de 2, las ventanas serán de 3 palabras, por lo que serán 5 ventanas en total.\n",
    "* Primera ventana: se toma del índice 1 a 3 de la frase y se opera $E_{1:3} \\cdot U = (2, 2, 0, -2, 0, 1)U$ obteniendo $(3,2,1)$ y aplicando tanh $(0.99505475, 0.96402758, 0.76159416)$\n",
    "* Segunda ventana: corresponde a $(0,-2,0,1,-2,1)$. De forma similar se obtiene de la convolución $(0,-1,4)$ y con tanh $(0, -0.76159416, -0.9993293)$\n",
    "* Tercera ventana: corresponde a $(0,1,-2,1,-2,0)$. De la convolución resulta $(2,2,-1)$ y por tanh $(0.96402758,  0.96402758, -0.76159416)$\n",
    "* Cuarta ventana: corresponde a $(-2,1,-2,0,2,-1)$. De la convolución resulta $(0,1,5)$ y por tanh $(0, 0.76159416, 0.9999092)$\n",
    "* Quinta ventana: corresponde a $(-2,0,2,-1,0,2)$. De la convolución resulta $(5,  3, -3)$ y por tanh $(0.9999092 ,  0.99505475, -0.99505475)$\n",
    "\n",
    "Aplicando max pooling se obtiene el vector $(0.9999092 , 0.99505475, 0.9999092)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tj1V_sAzZCHY"
   },
   "source": [
    "# Recurrent Neural Networks\n",
    "### Pregunta 4 (1 pt)\n",
    "Sea la siguiente oración: `El perro ladra` representada como una secuencia de vectores $x1,x2,x3$. Donde cada vector corresponde al word embedding de cada palabra, que a la vez es un vector de dos dimensiones\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "x1 &= Embed(El)    &= [1, 0] \\\\\n",
    "x2 &= Embed(perro) &= [-1, 1] \\\\\n",
    "x3 &= Embed(ladra) &= [1,1]\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Se tiene una red recurrente Elman: \n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\vec{s}_i &= R_{SRNN}\\left (\\vec{x}_i, \\vec{s}_{i-1}\\right ) = g \\left (\\vec{s}_{i-1}W^s + \\vec{x}_i W^x + \\vec{b}\\right ) \\\\\n",
    "\\vec{y}_i &= O_{SRNN}\\left(\\vec{s}_i\\right) = \\vec{s}_i \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "Con\n",
    "\\begin{equation}\n",
    "\\vec{s}_i, \\vec{y}_i \\in \\mathbb{R}^{d_s}, \\quad \\vec{x}_i \\in \\mathbb{R}^{d_x}, \\quad W^x \\in \\mathbb{R}^{d_x \\times d_s}, \\quad W^s \\in \\mathbb{R}^{d_s \\times d_s}, \\quad \\vec{b} \\in \\mathbb{R}^{d_s}\n",
    "\\end{equation}\n",
    "y donde los vectores de estado $s_i$ son de tres dimensiones, $ds= 3$.\n",
    "\n",
    "Sea\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\vec{s}_0 &= [0,0,0]\\\\\n",
    "W^x &= \\begin{pmatrix}\n",
    "0 &  0 & 1\\\\\n",
    "1 & -1 & 0\n",
    "\\end{pmatrix} \\\\\n",
    "W^s &= \\begin{pmatrix}\n",
    "1 & 0 &  1\\\\\n",
    "0 & 1 & -1\\\\\n",
    "1 & 1 &  1\n",
    "\\end{pmatrix} \\\\\n",
    "\\vec{b} &= [0, 0, 0] \\\\\n",
    "g(x) &= ReLu(x) = max(0, x)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "<br>\n",
    "\n",
    "Calcule manualmente los valores de $\\vec{s}_1, \\vec{s}_2,\\vec{s}_3$ y de $\\vec{y}_1, \\vec{y}_2,\\vec{y}_3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7M7sqIQV-Q3a"
   },
   "source": [
    "**Respuesta**\n",
    "como $\\vec{b}=[0,0,0]$ y $\\vec{s}_0=[0,0,0]$, el primer estado viene dado por $\\vec{s}_1=ReLu(\\vec{x}_1 W^x) = ReLU([0,0,1])=[0,0,1]$. Luego, $\\vec{y}_1 = [0,0,1]$.\n",
    "\n",
    "El segundo estado viene dado por $\\vec{s}_2=ReLu(\\vec{s}_1 W^s+\\vec{x}_2 W^x)=ReLu([1,1,1]+[1,-1,-1])=[2,0,0]$. Luego $\\vec{y}_2 = [2,0,0]$\n",
    "\n",
    "El tercer estado es $\\vec{s}_3=ReLu(\\vec{s}_2 W^s+\\vec{x}_3 W^x)= ReLU([2,0,2]+[1,-1,1])=[3,0,3]$. $\\vec{y}_3 = [3,0,3]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W4rAT6ELxRZW"
   },
   "source": [
    "### Pregunta 5 (0.5 pts)\n",
    "¿De qué forma las RNN y las CNN logran aprender representaciones específicas\n",
    "para la tarea objetivo? Compare la forma en que las RNN y las CNN aprenden con los modelos que usan *features* diseñadas manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6AXbQSgA_t8"
   },
   "source": [
    "**Respuesta**\n",
    "\n",
    "En general, las redes convolucionales y recurrentes pueden tomar como entrada datos sin demasiado preprocesamiento y logran aprender sus propiar representaciones internas de la entrada. Las capas convolucionales pueden aprender de la relación espacial del tensor de entrada mientras que la red recurrente puede aprender de relaciones temporales en los datos de entrada. Así, estas arquitecturas generan representaciones específicas para la tarea en que se estén utilizando. En cambio otros modelos dependen del conocimiento experto para diseñar features adecuadas para cada problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qxQIuO8axTUa"
   },
   "source": [
    "# Redes neuronales con PyTorch\n",
    "### Pregunta 6 (2 pts)\n",
    "En esta parte van a tener que implementar una red neuronal Feed Forward. Además, deberán entrenar el modelo usando uno de los datasets de TorchText. En la sección de la respuesta hay un esqueleto de lo que deben hacer, deberán completar los metodos del modelo y la parte asociada al entrenamiento la deben implementar ustedes. De todas formas, como les mencionamos en las auxiliares, el proceso de entrenamiento es bastante estándar, así que se pueden guiar en gran medida por los ejemplos que hemos visto y los que vamos a ver en las próximas auxiliares.\n",
    "\n",
    "### Bonus (0.5 pts)\n",
    "Agregue a la arquitectura una capa convolucional, para esto debe registrar el parametro $U$ en la red y realizar el computo de la convolución en el metodo forward de la red.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LVKEaQXZ3eGl"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Nos aseguramos que torchtext este en la ultima version\n",
    "!pip install --upgrade torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "dJ-wrzFO5mCC",
    "outputId": "de898848-3def-4c0f-84c0-09896b34ab12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ag_news_csv.tar.gz: 11.8MB [00:02, 4.64MB/s]\n",
      "120000lines [00:02, 41035.93lines/s]\n",
      "120000lines [00:05, 20857.30lines/s]\n",
      "7600lines [00:00, 20970.89lines/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Un ejemplo aleatorio\n",
      " (0, tensor([ 2745, 14596,  8788,  1954, 11252, 14596,    95,  1954,  2178,     5,\n",
      "           40,    82,  3927,    12,  1232,    98,    11,    31,   705, 11694,\n",
      "            2]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Trabajen con el siguiente dataset\n",
    "import os\n",
    "from random import choice\n",
    "from torchtext.datasets import AG_NEWS\n",
    "\n",
    "os.makedirs(\".data\", exist_ok=True)\n",
    "train_dataset, test_dataset = AG_NEWS(root=\".data\")\n",
    "\n",
    "print(\"\\nUn ejemplo aleatorio\\n\", choice(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "wSHn-hYi8XN8",
    "outputId": "46e96894-5243-4fd8-9898-2ff5b8d388e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3}\n",
      "('natural sunblock sun dims in strange ways ( space . com ) space . com - when '\n",
      " 'venus crossed the sun june 8 , showing up as a clear black dot to the '\n",
      " 'delight of millions of skywatchers around the world , astronomers noted '\n",
      " 'something less obvious the amount of sunlight reaching earth dipped by 0 . 1 '\n",
      " 'percent for a few hours .')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# Informacion relevante del dataset\n",
    "vocab = train_dataset.get_vocab()\n",
    "labels = train_dataset.get_labels()\n",
    "# El nombre de cada label lo pueden encontrar aqui\n",
    "# https://pytorch.org/text/datasets.html#ag-news, aunque no es necesario para \n",
    "# clasificar\n",
    "print(labels)\n",
    "# Un ejemplo convertido a texto\n",
    "pprint(\" \".join(vocab.itos[token] for token in choice(train_dataset)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXngUm9HxKvA"
   },
   "outputs": [],
   "source": [
    "# De aca para abajo viene su respuesta, completen las funciones en la red\n",
    "# y luego entrenen el modelo y evaluenlo usando los dataset que acaban de\n",
    "# cargar\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim,pad_idx,hidden_size,num_class, dropout=0.2): # Reemplacen el *args por sus argumento\n",
    "        # Aca deben registrar sus parametros. A lo menos necesitan\n",
    "        # una capa de embedding y un MLP basico (una capa lineal + softmax)\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, pad_idx)\n",
    "        self.fc1 = nn.Linear(embed_dim, hidden_size)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Aca debe programar la pasada hacia adelante\n",
    "        x = self.embedding(x).mean(dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPHyqgId96ra"
   },
   "outputs": [],
   "source": [
    "# El resto de su respuesta\n",
    "# Aca deben programar el entrenamiento de la red\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from itertools import zip_longest\n",
    "\n",
    "def generate_batch(batch):\n",
    "    return (\n",
    "        # En este caso como los labels son numeros, el tensor es de 1 dimension\n",
    "        # de tamanno batch_size\n",
    "        torch.tensor([item[0] for item in batch]),\n",
    "\n",
    "        # En este caso se retorna un tensor de 2 dimensiones, batch_size x N,\n",
    "        # donde N es mayor largo de los ejemplo en el batch. Aca se realiza\n",
    "        # padding de los ejemplos mas cortos.\n",
    "        torch.tensor(\n",
    "            list(\n",
    "                zip(\n",
    "                    *zip_longest(\n",
    "                        *[item[1] for item in batch], fillvalue=vocab[\"<pad>\"]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "def train(model, optimizer, train_ds, n_epoch, batch_size):\n",
    "    global device\n",
    "    data = DataLoader(train_ds, batch_size=batch_size,\n",
    "                    shuffle=True,collate_fn=generate_batch)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    for e in range(n_epoch):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        for i, (cls, text) in enumerate(data):\n",
    "            optimizer.zero_grad()\n",
    "            cls, text = cls.to(device), text.to(device)\n",
    "            output = model(text)\n",
    "            loss = criterion(output, cls)\n",
    "            train_loss+=loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_acc += (output.argmax(1) == cls).sum().item()\n",
    "        train_loss /= len(train_ds)\n",
    "        train_acc   /= len(train_ds)\n",
    "        print(\"Epoch {}, train_loss {:.2f} train_acc {:.2f}\".format(e+1,train_loss, train_acc*100))\n",
    "        \n",
    "def test(model, test_df, batch_size=64):\n",
    "    global device\n",
    "    data = DataLoader(test_df, batch_size=batch_size,\n",
    "                    shuffle=False,collate_fn=generate_batch)\n",
    "    test_acc = 0\n",
    "    for i, (cls, text) in enumerate(data):\n",
    "        cls, text = cls.to(device), text.to(device)\n",
    "        output = model(text)\n",
    "        test_acc += (output.argmax(1) == cls).sum().item()\n",
    "    return test_acc/len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM= 100\n",
    "HIDDEN_SIZE=200\n",
    "DROPOUT = 0.2\n",
    "LR = 0.001\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "classifier = CNNClassifier(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=EMBED_DIM,\n",
    "    pad_idx=vocab[\"<pad>\"],\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    dropout = DROPOUT,\n",
    "    num_class=len(labels)\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(classifier.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss 0.01 train_acc 84.52\n",
      "Epoch 2, train_loss 0.01 train_acc 92.00\n",
      "Epoch 3, train_loss 0.01 train_acc 93.94\n",
      "Epoch 4, train_loss 0.00 train_acc 95.20\n",
      "Epoch 5, train_loss 0.00 train_acc 96.00\n"
     ]
    }
   ],
   "source": [
    "train(classifier,optimizer, train_dataset,EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 90.684211%\n"
     ]
    }
   ],
   "source": [
    "classifier.eval()\n",
    "test_acc = test(classifier,test_dataset)\n",
    "print(\"Test Accuracy {:2f}%\".format(test_acc*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "minitarea4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
