{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:30:18.109327Z",
     "start_time": "2020-03-19T18:30:18.103344Z"
    }
   },
   "source": [
    "# Minitarea 1\n",
    "\n",
    "\n",
    "-----------------\n",
    "\n",
    "Nombre: Javier Urrutia\n",
    "\n",
    "Fecha de Entrega: Lunes 13 de Abril\n",
    "\n",
    "\n",
    "## Objetivos de la minitarea\n",
    "\n",
    "Este ejericio cuenta con varios objetivos principales: \n",
    "\n",
    "- Evaluar los contenidos de las primeras semanas de clases. En particular Information Retrieval (IR) y Vector Space Models. \n",
    "\n",
    "- Introducirlos a la programación en python enfocada en NLP.\n",
    "\n",
    "- Implementar un modelo básico de IR: *Term Frequency-Inverse Document Frequency (TF-IDF)*.\n",
    "\n",
    "\n",
    "## Instrucciones\n",
    "\n",
    "- El ejercicio consiste en:\n",
    "\n",
    "    - Responder preguntas relativas a los contenidos vistos en los videos y slides de las clases. \n",
    "    \n",
    "    - Implementar el modelo TF-IFD utilizando solo python, pandas y numpy. Está **PROHIBIDO** usar cualquier paquete que implemente dicho modelo (NLTK, spacy, scikit, etc...).\n",
    "\n",
    "- La minitarea es INDIVIDUAL.\n",
    "\n",
    "- Está demás decir que no se admiten copias, ni de código, ni de respuestas escritas. \n",
    "\n",
    "- La entrega debe ser por ucursos a mas tardar el día estipulado arriba. No se aceptan atrasos.\n",
    "\n",
    "- En el horario de auxiliar se abriran horarios de consulta en donde podrán preguntar acerca del ejercicio y en general, de todo el curso. \n",
    "\n",
    "- Cada punto equivale a 0.5 décimas de la nota de la minitarea.\n",
    "\n",
    "- Al revisar, tu código será ejecutado. Verifica que tu entrega no tenga errores.\n",
    "\n",
    "\n",
    "## Referencias\n",
    " \n",
    "Slides:\n",
    "    \n",
    "- [Introducción al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
    "- [Vector Space Model / Information Retrieval](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)    \n",
    "\n",
    "Videos: \n",
    "\n",
    "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 1](https://youtu.be/FXIVClF370w)\n",
    "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 2](https://youtu.be/f8nG1EMmPZk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "## Parte 1. \n",
    "\n",
    "La siguientes celdas contendrán preguntas acerca del contenido visto en clases y en el material del curso. La idea es contestar cada pregunta en su celda correspondiente. Las respuestas deben ser breves: máximo 3 lineas (salvo para la p3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P1) Son Natural Language Processing y Computational Linguistics lo mismo? (1 Punto)**\n",
    "\n",
    "    Respuesta: No, aunque tienen sobrelapes, son conceptos con focos distintos. NLP esta más dirigido a extraer información de alguna fuente escrita mientras que computational linguistics hace referencias a resolver problemas propios de la lingüistica mediante la computación.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P2) Por qué estudiar el lenguaje humano es difícil? (1 Punto)**\n",
    "\n",
    "    Respuesta: En gran parte porque aunque el vocabulario es finito, este se puede expresar en una cantidad infinita de oraciones para expresar distintas o las mimsas ideas. Además, entender el sigificado de cada palabra no necesariamente permite comprender el siginificado de una combinación de éstas pues puede cambiar con el contexto. Tampoco se puede entender la relacion entre dos palabras solo por las letras que las componen.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:45:25.544502Z",
     "start_time": "2020-03-19T18:45:25.537548Z"
    }
   },
   "source": [
    "\n",
    "**P3) Para el siguiente corpus:**\n",
    "\n",
    "    d1) I like human languages\n",
    "\n",
    "    d2) I like programming languages\n",
    "\n",
    "    d3) Spanish is my favorite language\n",
    "\n",
    "\n",
    "**Extraiga el vocabulario:**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Solamente usando tokenization (1.5 puntos)**\n",
    "\n",
    "Respuesta: \n",
    "\n",
    "        Vocabulario: I, like, human, languages, programming, spanish, is, my, favorite, language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Usando stemming (proponga sus propias reglas de stemming) y borrado de stopwords (indique cuales son sus stopwords) (1.5 puntos)**\n",
    "\n",
    "Respuesta: \n",
    "\n",
    "        Stopwords: I, is, my\n",
    "        \n",
    "        Reglas de Stemming: borrar s del final, doble m a una sola, borrar 'ing'\n",
    "        \n",
    "        Vocabulario: like, human, language, program, spanish, favorite\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:46:24.015666Z",
     "start_time": "2020-03-19T18:46:24.010706Z"
    }
   },
   "source": [
    "**P4) Conceptualmente cuál es la diferencia entre usar machine learning clásico (empirismo) y deep learning para un problema de NLP (Puede usar el análisis de sentimientos como ejemplo) (1 punto)**\n",
    "\n",
    "    Respuesta: La principal diferencia es que para obtener un buen rendimiento con el método clasico, se debe realizar feature engineering sobre el texto original, lo que puede llegar a ser bastante complicado y se necesita un buen conocimiento sobre el tema a resolver, como en el análisis de sentimientos. En cambio un sistema basado en deep learning puede procesar directamente el texto y aprender su propio espacio de características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:47:04.360754Z",
     "start_time": "2020-03-19T18:47:04.357763Z"
    }
   },
   "source": [
    "--------------\n",
    "\n",
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:57:05.868104Z",
     "start_time": "2020-03-19T18:57:05.863117Z"
    }
   },
   "source": [
    "Impementar TF-IDF. \n",
    "\n",
    "Esta parte, cada celda representa una función distinta por implementar. Se usará pandas para representar las matrices y arreglos que vayamos calculando. Siguiente a cada celda con una función por implementar habrá un ejemplo de como debería ser el output que tienen que lograr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.618054Z",
     "start_time": "2020-03-23T14:11:57.813136Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corpus**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset, cada string representa un documento. Observación: Corpus = Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.637916Z",
     "start_time": "2020-03-23T14:11:58.618054Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    't4 t3 t1 t4', 't5 t4 t2 t3 t5', 't2 t1 t4 t4', 't2 t3 t3 t1 t4',\n",
    "    't1 t4 t2 t2', 't2 t3 t2 t3 t2 t3'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtener vocabulario (1 punto)** \n",
    "\n",
    "Implementar la función `get_vocab(dataset)` que recibe el dataset y retorna un arreglo con cada palabra que aparece en el dataset. (sin duplicar). Observación: vocabulario = types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.657732Z",
     "start_time": "2020-03-23T14:11:58.637916Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vocab(dataset):\n",
    "    vocab = []\n",
    "    for s in dataset:\n",
    "        sl = s.split(\" \")\n",
    "        for t in sl:\n",
    "            if not t in vocab:\n",
    "                vocab.append(t)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t4', 't3', 't1', 't5', 't2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = get_vocab(dataset)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular Bag of Words (bow) (2 puntos)**\n",
    "\n",
    "implementar la función `calc_bow(dataset, vocab)` que toma el dataset y el vocabulario calculado en la parte anterior y retorna un pandas DataFrame en donde las columnas son el vocabulario y las filas representa las apariciones de cada una de las palabra los documento. En otras palabras, cada fila representa el bow de un determinado documento\n",
    "\n",
    "el bow de cada documento.\n",
    "\n",
    "Recordatorio - Bag of Words: Cuenta las apariciones de cada palabra en cada uno de los documentos. Por ejemplo:\n",
    "\n",
    "Por ejemplo, para los documentos: \n",
    "\n",
    "```\n",
    "d_0 = 'El perro ladra'\n",
    "d_1 = 'El perro come'\n",
    "\n",
    "```\n",
    "\n",
    "Deberíamos retornar:\n",
    "\n",
    "|   | el | perro | ladra | come |\n",
    "|---|----|-------|------|-------|\n",
    "| d_0 | 1  | 1     | 1    | 0     |\n",
    "| d_1 | 1  | 1     | 0    | 1     |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.680740Z",
     "start_time": "2020-03-23T14:11:58.673758Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_bow(dataset, vocab):\n",
    "    bow = pd.DataFrame(data=np.zeros((len(dataset),len(vocab)),dtype=int),columns=vocab)\n",
    "    for i,s in enumerate(dataset):\n",
    "        sl = s.split(\" \")\n",
    "        for t in sl:\n",
    "            bow.at[i,t]+=1  \n",
    "    return bow\n",
    "\n",
    "dataset_bow = calc_bow(dataset, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.694719Z",
     "start_time": "2020-03-23T14:11:58.683734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t4</th>\n",
       "      <th>t3</th>\n",
       "      <th>t1</th>\n",
       "      <th>t5</th>\n",
       "      <th>t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t4  t3  t1  t5  t2\n",
       "0   2   1   1   0   0\n",
       "1   1   1   0   2   1\n",
       "2   2   0   1   0   1\n",
       "3   1   2   1   0   1\n",
       "4   1   0   1   0   2\n",
       "5   0   3   0   0   3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T14:27:01.721767Z",
     "start_time": "2020-03-20T14:27:01.716781Z"
    }
   },
   "source": [
    "**Calcular TF (1 punto)**\n",
    "\n",
    "En esta sección debemos usar el dataframe calcular la matriz de TF normalizada por el máximo $\\text{ntf}_{i,j}$. Es decir, dividir cada bow en la cantidad de veces de la palabra que aparezca mas veces ese vector. \n",
    "\n",
    "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{max_i({\\text{tf}_{i,j})}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.717795Z",
     "start_time": "2020-03-23T14:11:58.697765Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_tf(dataset_bow):\n",
    "    maxtf=dataset_bow.max(axis=1)\n",
    "    return dataset_bow.divide(maxtf,axis=0)\n",
    "\n",
    "tf = calc_tf(dataset_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.737943Z",
     "start_time": "2020-03-23T14:11:58.717795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t4</th>\n",
       "      <th>t3</th>\n",
       "      <th>t1</th>\n",
       "      <th>t5</th>\n",
       "      <th>t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t4   t3   t1   t5   t2\n",
       "0  1.0  0.5  0.5  0.0  0.0\n",
       "1  0.5  0.5  0.0  1.0  0.5\n",
       "2  1.0  0.0  0.5  0.0  0.5\n",
       "3  0.5  1.0  0.5  0.0  0.5\n",
       "4  0.5  0.0  0.5  0.0  1.0\n",
       "5  0.0  1.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular IDF (1 punto)**\n",
    "\n",
    "\n",
    "Implementar `calc_idf(dataset_bow)`. Este debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el calculo de cada idf por palabra.\n",
    "\n",
    "Recordar que $idf_{t_i} = log_{10}\\frac{N}{n_i}$ con $N = $ número de documentos y $n_i = $ Número de documentos que contienen la palabra $t_i$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.777595Z",
     "start_time": "2020-03-23T14:11:58.737943Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_idf(dataset_bow):\n",
    "    idf = {}\n",
    "    N=len(dataset_bow)\n",
    "    for c in dataset_bow.columns:\n",
    "        ni = sum(dataset_bow[c]>0)\n",
    "        idf[c]=np.log10(N/ni)\n",
    "    return idf\n",
    "\n",
    "idf = calc_idf(dataset_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.792834Z",
     "start_time": "2020-03-23T14:11:58.777595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t4': 0.07918124604762482,\n",
       " 't3': 0.17609125905568124,\n",
       " 't1': 0.17609125905568124,\n",
       " 't5': 0.7781512503836436,\n",
       " 't2': 0.07918124604762482}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular TF-IDF (1 punto)**\n",
    "\n",
    "Por último, implementar `calc_tf_idf(tf, idf)`. Esta debe cumplir que \n",
    "\n",
    "$$tf{-}idf = tf_{i,j} * idf_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.817896Z",
     "start_time": "2020-03-23T14:11:58.792834Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_tf_idf(tf, idf):\n",
    "    tf_idf = tf.copy()\n",
    "    for c in dataset_bow.columns:\n",
    "        tf_idf[c]*=idf[c]\n",
    "    return tf_idf\n",
    "\n",
    "tf_idf = calc_tf_idf(tf, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.837641Z",
     "start_time": "2020-03-23T14:11:58.817896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t4</th>\n",
       "      <th>t3</th>\n",
       "      <th>t1</th>\n",
       "      <th>t5</th>\n",
       "      <th>t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079181</td>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039591</td>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.039591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.079181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039591</td>\n",
       "      <td>0.176091</td>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         t4        t3        t1        t5        t2\n",
       "0  0.079181  0.088046  0.088046  0.000000  0.000000\n",
       "1  0.039591  0.088046  0.000000  0.778151  0.039591\n",
       "2  0.079181  0.000000  0.088046  0.000000  0.039591\n",
       "3  0.039591  0.176091  0.088046  0.000000  0.039591\n",
       "4  0.039591  0.000000  0.088046  0.000000  0.079181\n",
       "5  0.000000  0.176091  0.000000  0.000000  0.079181"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus: Hacer una función para realizar una Query (2 puntos extra)**\n",
    "\n",
    "`calc_query(query, dataset)` función debe retornar un ranking con los documentos mas relevantes para la palabra consultada. \n",
    "\n",
    "Sugerencias:\n",
    "\n",
    "- Primero, recalcular la matriz TF-IDF usando el dataset mas la query. Usen las funciones anteriores para calcular la matriz.\n",
    "- Luego, usar similitud coseno para comparar los documentos ya precalculados y la consulta. (deben implementar dicha función usando las herramientas básicas de numpy).\n",
    "- A partir de eso, retornar un ranking con los documentos mas similares.\n",
    "\n",
    "Deben reportar por lo menos 2 ejemplos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T13:06:17.829181Z",
     "start_time": "2020-03-24T13:06:17.825192Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_cos_sim(v1,v2):\n",
    "    #Calcular similitud coseno\n",
    "    num=np.dot(v1,v2)\n",
    "    nv1=np.sqrt(np.dot(v1,v1))\n",
    "    nv2=np.sqrt(np.dot(v2,v2))\n",
    "    return num/(nv1*nv2)\n",
    "\n",
    "def calc_query(query, dataset):\n",
    "    #obtener matriz tf-idf\n",
    "    ds_query = dataset + [query]\n",
    "    vocab = get_vocab(ds_query)\n",
    "    ds_bow = calc_bow(ds_query,vocab)\n",
    "    tf=calc_tf(ds_bow)\n",
    "    idf=calc_idf(ds_bow)\n",
    "    tf_idf=calc_tf_idf(tf,idf)\n",
    "    #Obtener ranking\n",
    "    cos_sim=[]\n",
    "    for i in range(len(tf_idf)-1):\n",
    "        cos_sim.append(calc_cos_sim(tf_idf.iloc[i],tf_idf.iloc[-1]))\n",
    "    rank = np.argsort(cos_sim)[::-1]\n",
    "    res=[]\n",
    "    for i in rank:\n",
    "        res.append(dataset[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t2 t1 t4 t4',\n",
       " 't4 t3 t1 t4',\n",
       " 't1 t4 t2 t2',\n",
       " 't2 t3 t3 t1 t4',\n",
       " 't5 t4 t2 t3 t5',\n",
       " 't2 t3 t2 t3 t2 t3']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_query(\"t1 t4\",dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t1 t4 t2 t2',\n",
       " 't2 t1 t4 t4',\n",
       " 't2 t3 t3 t1 t4',\n",
       " 't4 t3 t1 t4',\n",
       " 't2 t3 t2 t3 t2 t3',\n",
       " 't5 t4 t2 t3 t5']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_query(\"t2 t2 t1\",dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02177373548356202"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usar dato reales (Opcional, sin puntaje)**\n",
    "\n",
    "Adicionalmente, existe la alternativa de probar tu implementación de tf-idf con un dataset de noticias:\n",
    "\n",
    "El modelo que creaste anteriormente no debería dejar de funcionar si cargas este dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:42.470019Z",
     "start_time": "2020-03-23T14:11:33.935341Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "BASE_URL = 'https://github.com/dccuchile/CC6205/releases/download/Data/{}.json'\n",
    "\n",
    "dataset = pd.concat([\n",
    "    pd.read_json(BASE_URL.format('biobio_nacional')),\n",
    "    pd.read_json(BASE_URL.format('biobio_opinion')),\n",
    "    pd.read_json(BASE_URL.format('biobio_internacional')),\n",
    "    pd.read_json(BASE_URL.format('biobio_sociedad')),\n",
    "    pd.read_json(BASE_URL.format('biobio_economia'))\n",
    "])\n",
    "\n",
    "\n",
    "def clean_doc(doc):\n",
    "    return ' '.join(\n",
    "        list(\n",
    "            filter(\n",
    "                lambda x: x != '',\n",
    "                re.sub(\"\\?|\\¿|\\:|\\!|\\¡|\\(|\\)|\\t|\\n|“|”|\\\"|\\'|\\s\\s+|\\.|\\,|\\;\",\n",
    "                       \" \", doc.lower()).split(' '))))\n",
    "\n",
    "\n",
    "dataset = list(\n",
    "    map(lambda x: clean_doc(x[0] + '.' + x[1]), dataset[['title',\n",
    "                                                         'content']].values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
